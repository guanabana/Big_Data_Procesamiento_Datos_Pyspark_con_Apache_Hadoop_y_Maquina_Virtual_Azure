# Big_Data_Procesamiento_Datos_Pyspark_con_Apache_Hadoop_y_Maquina_Virtual_Azure
El objetivo de este ejercicio es familiarizarse con el uso de pyspark en la etapa de Transformación en un proceso ETL dentro de un Datalake instalado hadoop HDFS. Se busca interiorizar el concepto de SparkSession y practicar consultas según sintaxis pyspark y sql. 
